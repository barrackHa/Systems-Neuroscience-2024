#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=blue"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\boxbgcolor #007df2
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Systems Neuroscience
\begin_inset Newline linebreak
\end_inset

76901
\begin_inset Newline linebreak
\end_inset

Solution 1st Assignment
\end_layout

\begin_layout Author
Barak Haim 
\begin_inset Newline linebreak
\end_inset

1
\end_layout

\begin_layout Date
11/02/2024
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Data exploration - visualize the signals and their relation to the stimuli
\end_layout

\begin_layout Subsection
1.a
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q1a.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
In this figure we see different neurons respond differently to different
 stimuli.
 
\end_layout

\begin_layout Subsection
1.b
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q1b.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
By looking at the whole population we can see how neurons behave in the
 
\begin_inset Quotes eld
\end_inset

big picture
\begin_inset Quotes erd
\end_inset

.
 We can se some stimuli cause a large number of neurons to fire together
 while others are more local.
\end_layout

\begin_layout Subsection
1.c
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q1c.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
We can see neurons firing well after stimulus ends.
\end_layout

\begin_layout Subsection
1.d
\end_layout

\begin_layout Paragraph
See matrix in the code.
\end_layout

\begin_layout Section
Tuning curves
\end_layout

\begin_layout Subsection
2.a
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q2a.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
Here we can see 5 exemplar neuronal tuning cures.
 For some we can see a distinct preferred direction (e.g.
 - #0 is tuned to around 20 deg, #200 to -75), while others respond to few
 different directions (e.g.-#400 and #1080).
 It's important to note some firing rates are extremely variable.
 In conclusion, we can see here the system is more complex than simply a
 neuron per direction.
 
\end_layout

\begin_layout Subsection
2.b
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q2b.png
	scale 50
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Paragraph
It looks generally the fish is more sensitive to stimuli for the far ends
 of its field of view.
 Maybe this is enables it more sensitivity to stimuli (predators or prey)
 which have a small chance of being detected.
 
\end_layout

\begin_layout Subsection
2.c
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q2c.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
We can see clusters of neurons with similar turning cures.
 Maybe this is due to Hebbian learning - neurons which fire together wire
 together - keeping them close by is more efficient energetically and keeps
 latency at it's minimum.
\end_layout

\begin_layout Section
Correlation in the data and dimensionality reduction
\end_layout

\begin_layout Subsection
3.a
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q3a.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
PC1 represents the dimension with greatest variance in the data.
 PC2 is the second most variable after PC1 and orthogonal to it.
 In our case, we have matrix A with 1089 rows of neurons and for each 215
 stimuli features.
 PCs 1 and 2 represent the combination of stimuli which are the most crucial
 to understand how the neurons behave with regards to stimulation.
 We can see a 
\begin_inset Quotes eld
\end_inset

V
\begin_inset Quotes erd
\end_inset

 shape similar to the spatial data.
 Also, we can see clusters by color (i.e.
 preferred direction).
 We can also see how the order of the clusters match the colorbar along
 the 
\begin_inset Quotes eld
\end_inset

V
\begin_inset Quotes erd
\end_inset

 shape.
 
\end_layout

\begin_layout Subsection
3.b
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q3b.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
Here we have the transposed matrix A from the previous question, i.e.
 rows of stimuli and columns of neurons.
 This is a representation of the different stimuli by variance in the neuronal
 space.
 Again, we see the distinct 
\begin_inset Quotes eld
\end_inset

V
\begin_inset Quotes erd
\end_inset

 shape and how proximity in the neuronal 2D PC space is correlated with
 closeness to stimuli type.
\end_layout

\begin_layout Subsection
3.c
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q3c.png
	scale 60
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
Here we see the data spanned on an arc.
 Again, proximity in the 2D tNSE space is correlated with closeness to stimuli
 type.
 All in all, pretty similar to 3B.
 In general, tNSE is more robust to outliers, is more suitable for non-linearly
 separable data and better at preserving distances.
 In the general case, I hypothesize tNSE would be better for non-linearly
 separable data.
 
\end_layout

\begin_layout Subsection
3.d
\end_layout

\begin_layout Paragraph
It seems like a single neuron may have 
\begin_inset Quotes eld
\end_inset

preferences
\begin_inset Quotes erd
\end_inset

 with regards to stimulus, however, in order to understand how stimuli are
 represented, we must look at the network level.
 
\end_layout

\begin_layout Section
Decoding the presented stimulus using neural activity only
\end_layout

\begin_layout Subsection
4.a
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q4a.png
	scale 60
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Paragraph
LDA assumes there's a hyper-plane which separates 2 distinct clusters (around
 which are centered around their respective means and have identical covariances
).
 LDA then finds the hyper-plane (as seen in the figure) using the labels
 and data given to it.
 We can then measure how well the model did by asking the question how many
 misclassifications are there regarding the test dataset.
 The so called 
\begin_inset Quotes eld
\end_inset

test-set
\begin_inset Quotes erd
\end_inset

 was not seen by the model during its training and so should give an objective
 estimate to 
\begin_inset Quotes eld
\end_inset

real
\begin_inset Quotes erd
\end_inset

 inputs.
 We can look at the confusion matrix in the next question.
\end_layout

\begin_layout Paragraph
Moreover, we can ask whats the rate of true labels (True Positives AKA TP)
 out of those who are real true (TP + False Negatives AKA FP).
 Also, we can ask how many missed classification were there or what is their
 rate.
 This is computed in subsection 
\begin_inset Quotes eld
\end_inset

c
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsection
4.b
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q4b.png
	scale 60
	rotateOrigin center

\end_inset


\end_layout

\begin_layout Paragraph
We see there are no misclassifications with regards to this train-set.
 We can see one misclassification in the train-set above.
 Overall this is a pretty good classification though still, it doesn't say
 much about the general training error of all possible data.
 
\end_layout

\begin_layout Subsection
4.c
\end_layout

\begin_layout Paragraph
Both accuracy and sensitivity are 
\begin_inset Formula $100\%$
\end_inset

.
 This means the classification is the best we can hope for under these condition
s and this test-set.
\end_layout

\begin_layout Subsection
4.d
\end_layout

\begin_layout Paragraph
\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q4d_lda.png
	scale 50
	rotateOrigin centerTop

\end_inset


\begin_inset Graphics
	filename /Users/barak/Projects/systems_neuroscience/figs/q4d_cm.png
	scale 50
	rotateOrigin centerTop

\end_inset


\end_layout

\begin_layout Paragraph
In this case, the accuracy rate is 78% and sensitivity rate is 38%.
 We can also see by the confusion matrix and the boundary line that a large
 number of the 
\begin_inset Quotes eld
\end_inset

-75
\begin_inset Quotes erd
\end_inset

 neurons are classified as 
\begin_inset Quotes eld
\end_inset

-60
\begin_inset Quotes erd
\end_inset

.
 This is not very impressive....
 We can see the performance of LDA is not necessarily good or bad but depends
 on the data.
 Here it seems the data is not linearly separable and the model is not robust
 enough in order to handle it.
 
\end_layout

\begin_layout Subsection
4.e
\end_layout

\begin_layout Paragraph
LDA assumes the data is: 
\end_layout

\begin_layout Itemize
Multivariate normality: Independent variables are normally distributed.
\end_layout

\begin_layout Itemize
Covariances among group variables are the same across levels of predictors.
 
\end_layout

\begin_layout Itemize
Multi-collinear.
\end_layout

\begin_layout Itemize
i.i.d.
\end_layout

\begin_layout Paragraph
In our case, it seems the data isn't necessarily normally distributed or,
 maybe not i.i.d.
 
\end_layout

\begin_layout Subsection
4.f
\end_layout

\begin_layout Paragraph
We can use a random forest in order to deal with this classification problem.
 First, i'd use PCA again on matrix A, this time not limiting it to just
 2 dimensions.
 Then, I'd feed the data as a to the random-forest classifier in order to
 classify according to different stimuli.
 
\end_layout

\end_body
\end_document
